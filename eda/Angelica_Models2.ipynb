{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#import pathlib\n",
    "#src_path = pathlib.Path().absolute().parent / \"src\"\n",
    "#sys.path.append(str(src_path))\n",
    "#import data_functions\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline \n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    " \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#import model features pipeline\n",
    "strict_pp = src_path / 'strict_pre_pipeline_v4.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import pathlib\n",
    "src_path = pathlib.Path().absolute().parent / \"src\"\n",
    "sys.path.append(str(src_path))\n",
    "import data_functions\n",
    "import custom_transformers as ct\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.compose import  make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train = data_functions.get_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import data_functions\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "class BinInstaller(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _to_df(self, X):\n",
    "        if type(X) != pd.DataFrame:\n",
    "            if type(X) != list:\n",
    "                if type(X) == pd.Series:\n",
    "                    data = pd.DataFrame(X)\n",
    "                elif type(X) == dict:\n",
    "                    data = pd.DataFrame([X])\n",
    "                else:\n",
    "                    raise ValueError('X must be a dataframe, list, series, or dictionary  object.')\n",
    "            else:\n",
    "                data = pd.DataFrame(X)\n",
    "        else:\n",
    "            data = X.copy()\n",
    "        return data\n",
    "        \n",
    "    def transform(self, X):\n",
    "        data = self._to_df(X)\n",
    "        others = data['installer'].value_counts().index[data['installer'].value_counts() < 10]\n",
    "        is_other = lambda x: 'Other' if x in others else x\n",
    "        data['installer'] = data['installer'].map(is_other)\n",
    "        data['installer'] = data['installer'].fillna('Unknown')\n",
    "        return data\n",
    "\n",
    "    \n",
    "class TransformConstructionYear(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.current_year = datetime.now().year\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _to_df(self, X):\n",
    "        if type(X) != pd.DataFrame:\n",
    "            if type(X) != list and type(X) != np.ndarray:\n",
    "                if type(X) == pd.Series:\n",
    "                    data = pd.DataFrame(X)\n",
    "                elif type(X) == dict:\n",
    "                    data = pd.DataFrame([X])\n",
    "                else:\n",
    "                    raise ValueError('X must be a dataframe, list, series, or dictionary  object.')\n",
    "                    \n",
    "            else:\n",
    "                data = pd.DataFrame(X)\n",
    "        else:\n",
    "            data = X.copy()\n",
    "        return data\n",
    "    \n",
    "    def _bin_data(self, x):\n",
    "        if x == 0:\n",
    "            return 0 \n",
    "        else:\n",
    "            return self.current_year - x \n",
    "        \n",
    "    def transform(self, X):\n",
    "        data = self._to_df(X)\n",
    "        data['construction_year'] = data['construction_year'].apply(self._bin_data)\n",
    "        return data\n",
    "    \n",
    "class ChooseStrictFeatures(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _to_df(self, X):\n",
    "        if type(X) != pd.DataFrame:\n",
    "            if type(X) != list:\n",
    "                if type(X) == pd.Series:\n",
    "                    data = pd.DataFrame(X)\n",
    "                elif type(X) == dict:\n",
    "                    data = pd.DataFrame([X])\n",
    "                else:\n",
    "                    raise ValueError('X must be a dataframe, list, series, or dictionary  object.')\n",
    "            else:\n",
    "                data = pd.DataFrame(X)\n",
    "        else:\n",
    "            data = X.copy()\n",
    "        return data\n",
    "        \n",
    "    def transform(self, X):\n",
    "        data = self._to_df(X)\n",
    "        data = data[data_functions.get_strict_features()]\n",
    "        return data\n",
    "    \n",
    "# class ChooseLooseFeatures(TransformerMixin, BaseEstimator):\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "    \n",
    "#     def _to_df(self, X):\n",
    "#         if type(X) != pd.DataFrame:\n",
    "#             if type(X) != list:\n",
    "#                 if type(X) == pd.Series:\n",
    "#                     data = pd.DataFrame(X)\n",
    "#                 elif type(X) == dict:\n",
    "#                     data = pd.DataFrame([X])\n",
    "#                 else:\n",
    "#                     raise ValueError('X must be a dataframe, list, series, or dictionary  object.')\n",
    "#             else:\n",
    "#                 data = pd.DataFrame(X)\n",
    "#         else:\n",
    "#             data = X.copy()\n",
    "#         return data\n",
    "        \n",
    "#     def transform(self, X):\n",
    "#         data = self._to_df(X)\n",
    "#         data = data[data_functions.get_loose_features()]\n",
    "#         return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_pp_pipe = Pipeline([('feature_selector', ChooseStrictFeatures()),\n",
    "                           ('bin_installer', ct.BinInstaller()),\n",
    "                           ('column_transformer', make_column_transformer((SimpleImputer(missing_values = 0.0), ['construction_year']),\n",
    "                                                            (SimpleImputer(), data_functions.get_numeric_features(data_functions.get_strict_features())),\n",
    "                                                            (ct.TransformConstructionYear(), ['construction_year']),\n",
    "                                                            (StandardScaler(), data_functions.get_numeric_features(data_functions.get_strict_features())),\n",
    "                                                            (OneHotEncoder(handle_unknown = 'ignore', sparse = False), data_functions.get_categorical_features(data_functions.get_strict_features())),\n",
    "                                                            remainder = 'drop')),\n",
    "                           ('up_sample', SMOTE(random_state = 42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data = strict_pp_pipe.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_resamp= pd.DataFrame(resampled_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps of the chain should be estimators that implement fit and transform or fit_resample (but not both) or be a string 'passthrough' '(array([[ 1.99900000e+03,  6.00000000e+03,  1.39000000e+03, ...,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n       [ 2.01000000e+03,  0.00000000e+00,  1.39900000e+03, ...,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n       [ 2.00900000e+03,  2.50000000e+01,  6.86000000e+02, ...,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n       ...,\n       [ 1.97719360e+03,  0.00000000e+00,  8.27015993e+01, ...,\n         0.00000000e+00,  0.00000000e+00,  2.98400650e-01],\n       [ 1.98800000e+03,  0.00000000e+00, -3.50885787e+01, ...,\n         5.65397631e-01,  0.00000000e+00,  4.34602369e-01],\n       [ 1.99681469e+03,  0.00000000e+00,  0.00000000e+00, ...,\n         1.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),          status_group\n0          functional\n1          functional\n2          functional\n3      non functional\n4          functional\n...               ...\n96772  non functional\n96773  non functional\n96774  non functional\n96775  non functional\n96776  non functional\n\n[96777 rows x 1 columns])' (type <class 'tuple'>) doesn't)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-162acb0d022a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstrict_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'preprocessor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresampled_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'dTree_classifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/water_well-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/water_well-env/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory, verbose)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/water_well-env/lib/python3.6/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0;34m\"be estimators that implement fit and transform or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0;34m\"fit_resample (but not both) or be a string 'passthrough' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0;34m\"'%s' (type %s) doesn't)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 )\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps of the chain should be estimators that implement fit and transform or fit_resample (but not both) or be a string 'passthrough' '(array([[ 1.99900000e+03,  6.00000000e+03,  1.39000000e+03, ...,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n       [ 2.01000000e+03,  0.00000000e+00,  1.39900000e+03, ...,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n       [ 2.00900000e+03,  2.50000000e+01,  6.86000000e+02, ...,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n       ...,\n       [ 1.97719360e+03,  0.00000000e+00,  8.27015993e+01, ...,\n         0.00000000e+00,  0.00000000e+00,  2.98400650e-01],\n       [ 1.98800000e+03,  0.00000000e+00, -3.50885787e+01, ...,\n         5.65397631e-01,  0.00000000e+00,  4.34602369e-01],\n       [ 1.99681469e+03,  0.00000000e+00,  0.00000000e+00, ...,\n         1.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),          status_group\n0          functional\n1          functional\n2          functional\n3      non functional\n4          functional\n...               ...\n96772  non functional\n96773  non functional\n96774  non functional\n96775  non functional\n96776  non functional\n\n[96777 rows x 1 columns])' (type <class 'tuple'>) doesn't)"
     ]
    }
   ],
   "source": [
    "strict_model = Pipeline([('preprocessor', resampled_data), ('dTree_classifier', DecisionTreeClassifier())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(strict_model, x_train, y_train, cv = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = open(strict_pp, 'rb')\n",
    "#strict_v4 = pickle.load(file)\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strict_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strict_v4.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_tr_val, x_te_val, y_tr_val, y_te_val = train_test_split(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#resampled_data = strict_v4.fit_resample(x_tr_val, y_tr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_tr_resamp= pd.DataFrame(resampled_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_tr_val, x_te_val, y_tr_val, y_te_val = train_test_split(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = open(strict_pickle_path, 'rb')\n",
    "#strict_v4 = pickle.load(file)\n",
    "#file.close()\n",
    "#x_tr_val, x_te_val, y_tr_val, y_te_val = train_test_split(x_train, y_train)\n",
    "#resampled_data = strict_v4.fit_resample(x_tr_val, y_tr_val)\n",
    "#x_tr_resamp= pd.DataFrame(resampled_data[0])\n",
    "#y_tr_resamp = pd.DataFrame(resampled_data[1])\n",
    "\n",
    "#x_tr_resamp= x_tr_resamp.drop(columns=[0,1,2,3,4,5], axis = 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:water_well-env] *",
   "language": "python",
   "name": "conda-env-water_well-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
